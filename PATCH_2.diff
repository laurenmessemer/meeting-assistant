--- /dev/null
+++ b/app/tools/memory_processing.py
@@ -0,0 +1,120 @@
+"""Memory processing module for synthesizing insights from past context."""
+
+from typing import Dict, Any, Optional, List
+from app.llm.gemini_client import GeminiClient
+
+
+def sanitize_memory_value(value: Optional[str]) -> str:
+    """
+    Sanitize a single memory value.
+    
+    Args:
+        value: Memory value string (may be None)
+    
+    Returns:
+        Sanitized string (truncated to 500 chars, stripped whitespace)
+    """
+    if not value:
+        return ""
+    
+    # Strip whitespace
+    sanitized = value.strip()
+    
+    # Truncate to 500 characters
+    if len(sanitized) > 500:
+        sanitized = sanitized[:500] + "..."
+    
+    return sanitized
+
+
+def sanitize_past_context(past_context: Optional[List[Dict[str, Any]]]) -> List[str]:
+    """
+    Sanitize past context list.
+    
+    Args:
+        past_context: List of memory entry dicts with 'value' key
+    
+    Returns:
+        List of sanitized memory value strings
+    """
+    if not past_context:
+        return []
+    
+    sanitized = []
+    for mem in past_context:
+        if isinstance(mem, dict):
+            value = mem.get("value", "")
+            sanitized_value = sanitize_memory_value(value)
+            if sanitized_value:  # Only add non-empty values
+                sanitized.append(sanitized_value)
+    
+    return sanitized
+
+
+async def synthesize_memory(
+    past_context: Optional[List[Dict[str, Any]]],
+    llm_client: GeminiClient
+) -> Dict[str, str]:
+    """
+    Synthesize insights from past context using LLM.
+    
+    Args:
+        past_context: List of memory entry dicts with 'value' key
+        llm_client: LLM client for synthesis
+    
+    Returns:
+        Dictionary with structured insights:
+        {
+            "communication_style": str,
+            "client_history": str,
+            "recurring_topics": str,
+            "open_loops": str,
+            "preferences": str
+        }
+        All fields are empty strings if no memory exists or synthesis fails.
+    """
+    # Sanitize past context
+    sanitized_memories = sanitize_past_context(past_context)
+    
+    # If no memories, return empty insights
+    if not sanitized_memories:
+        return {
+            "communication_style": "",
+            "client_history": "",
+            "recurring_topics": "",
+            "open_loops": "",
+            "preferences": ""
+        }
+    
+    # Build context for LLM
+    memories_text = "\n".join([f"- {mem}" for mem in sanitized_memories])
+    
+    prompt = f"""Analyze the following past meeting interactions and extract structured insights.
+
+Past Meeting Context:
+{memories_text}
+
+Extract and synthesize the following insights:
+
+1. Communication Style: How does the user typically communicate? What tone, formality level, and writing patterns do you observe?
+
+2. Client History: What patterns emerge about this specific client's prior meetings? What topics, concerns, or themes recur?
+
+3. Recurring Topics: What themes or subjects appear across multiple interactions? What topics are frequently discussed?
+
+4. Open Loops: What commitments, TODOs, or action items were mentioned but may not have been completed? What follow-ups are pending?
+
+5. Preferences: What preferences does the user have for summarization style, follow-up tone, or meeting brief format?
+
+Respond in JSON format:
+{{
+    "communication_style": "Brief description of communication patterns",
+    "client_history": "Patterns about this client's prior meetings",
+    "recurring_topics": "Themes that appear across interactions",
+    "open_loops": "Pending commitments or TODOs",
+    "preferences": "User preferences for tone and format"
+}}
+
+If you cannot extract meaningful insights for any field, return an empty string for that field."""
+
+    try:
+        result = await llm_client.llm_chat(
+            prompt=prompt,
+            response_format="JSON",
+            temperature=0.4,  # Lower temperature for more consistent extraction
+        )
+        
+        # Ensure we have the expected structure
+        if isinstance(result, dict):
+            return {
+                "communication_style": result.get("communication_style", ""),
+                "client_history": result.get("client_history", ""),
+                "recurring_topics": result.get("recurring_topics", ""),
+                "open_loops": result.get("open_loops", ""),
+                "preferences": result.get("preferences", "")
+            }
+        else:
+            # Fallback: return empty insights
+            return {
+                "communication_style": "",
+                "client_history": "",
+                "recurring_topics": "",
+                "open_loops": "",
+                "preferences": ""
+            }
+    except Exception:
+        # On any error, return empty insights (fail gracefully)
+        return {
+            "communication_style": "",
+            "client_history": "",
+            "recurring_topics": "",
+            "open_loops": "",
+            "preferences": ""
+        }
+
--- a/app/tools/summarization.py
+++ b/app/tools/summarization.py
@@ -3,6 +3,7 @@
 from typing import Dict, Any, Optional
 from app.llm.gemini_client import GeminiClient
 from app.llm.prompts import SUMMARIZATION_TOOL_PROMPT
+from app.tools.memory_processing import synthesize_memory
 
 
 class SummarizationTool:
@@ -14,6 +15,7 @@ class SummarizationTool:
     async def summarize_meeting(
         self,
         transcript: Optional[str] = None,
         meeting_title: Optional[str] = None,
         meeting_date: Optional[str] = None,
         recording_date: Optional[str] = None,
         attendees: Optional[str] = None,
-        has_transcript: bool = True
+        has_transcript: bool = True,
+        past_context: Optional[List[Dict[str, Any]]] = None
     ) -> Dict[str, Any]:
         """
         Summarize a meeting and extract decisions/actions.
@@ -26,6 +28,7 @@ class SummarizationTool:
             recording_date: Zoom recording date for display
             attendees: Comma-separated list of attendee names
             has_transcript: Whether transcript is available (default: True)
+            past_context: Optional list of past meeting memories for context
         
         Returns:
             Dictionary with summary, decisions, and metadata
@@ -42,6 +45,28 @@ class SummarizationTool:
         recording_date_str = recording_date or "N/A"
         attendees_display = attendees or "Not specified"
         
+        # Synthesize memory insights if past_context provided
+        insights = {
+            "communication_style": "",
+            "client_history": "",
+            "recurring_topics": "",
+            "open_loops": "",
+            "preferences": ""
+        }
+        if past_context:
+            try:
+                insights = await synthesize_memory(past_context, self.llm)
+            except Exception:
+                # Fail gracefully - continue without memory insights
+                pass
+        
+        # Build memory context section if insights exist
+        memory_context_section = ""
+        if any(insights.values()):  # Only include if at least one field has content
+            memory_context_section = f"""
+Context From Prior Meetings:
+- Communication style: {insights['communication_style']}
+- Client history: {insights['client_history']}
+- Recurring themes: {insights['recurring_topics']}
+- Open loops: {insights['open_loops']}
+- User preferences: {insights['preferences']}
+"""
+            # Enforce 1200 character limit on memory context section
+            if len(memory_context_section) > 1200:
+                memory_context_section = memory_context_section[:1200] + "..."
+        
         # Generate structured summary using LLM
         if not has_transcript:
             # Generate summary without transcript - just calendar information
-            prompt = f"""Create a meeting summary based on the available calendar information. Note that no Zoom recording is available for this meeting.
+            prompt = f"""Create a meeting summary based on the available calendar information. Note that no Zoom recording is available for this meeting.
+{memory_context_section}
 
 Meeting Information:
 - Title: {title}
@@ -82,7 +107,7 @@ class SummarizationTool:
 Format your response using the EXACT section headers shown above (with # and ## markdown formatting). Be clear, concise, and well-organized."""
         else:
             # Generate summary with transcript
-            prompt = f"""Analyze the following meeting transcript and create a comprehensive, well-structured summary.
+            prompt = f"""Analyze the following meeting transcript and create a comprehensive, well-structured summary.
+{memory_context_section}
 
 Meeting Information:
 - Title: {title}
--- a/app/tools/meeting_brief.py
+++ b/app/tools/meeting_brief.py
@@ -3,6 +3,7 @@
 from typing import Dict, Any, Optional
 from app.llm.gemini_client import GeminiClient
 from app.llm.prompts import SUMMARIZATION_TOOL_PROMPT
+from app.tools.memory_processing import synthesize_memory
 
 
 class MeetingBriefTool:
@@ -14,6 +15,7 @@ class MeetingBriefTool:
     async def generate_brief(
         self,
         client_name: Optional[str] = None,
         meeting_title: Optional[str] = None,
         meeting_date: Optional[str] = None,
         attendees: Optional[str] = None,
         previous_meeting_summary: Optional[str] = None,
-        client_context: Optional[str] = None
+        client_context: Optional[str] = None,
+        past_context: Optional[List[Dict[str, Any]]] = None
     ) -> Dict[str, Any]:
         """
         Generate a meeting brief.
@@ -25,6 +27,7 @@ class MeetingBriefTool:
             attendees: Comma-separated list of attendees
             previous_meeting_summary: Optional summary of previous meeting for context
             client_context: Optional client context/information
+            past_context: Optional list of past meeting memories for context
         
         Returns:
             Dictionary with brief content
         """
+        # Synthesize memory insights if past_context provided
+        insights = {
+            "communication_style": "",
+            "client_history": "",
+            "recurring_topics": "",
+            "open_loops": "",
+            "preferences": ""
+        }
+        if past_context:
+            try:
+                insights = await synthesize_memory(past_context, self.llm)
+            except Exception:
+                # Fail gracefully - continue without memory insights
+                pass
+        
+        # Build memory context section if insights exist
+        memory_context_section = ""
+        if any(insights.values()):  # Only include if at least one field has content
+            memory_context_section = f"""
+Context From Prior Meetings:
+- Communication style: {insights['communication_style']}
+- Client history: {insights['client_history']}
+- Recurring themes: {insights['recurring_topics']}
+- Open loops: {insights['open_loops']}
+- User preferences: {insights['preferences']}
+"""
+            # Enforce 1200 character limit on memory context section
+            if len(memory_context_section) > 1200:
+                memory_context_section = memory_context_section[:1200] + "..."
+        
         # Build prompt for meeting brief
         context_parts = []
         
@@ -50,6 +73,8 @@ class MeetingBriefTool:
         if previous_meeting_summary:
             context_parts.append(f"\nPrevious Meeting Summary:\n{previous_meeting_summary}")
         
+        if memory_context_section:
+            context_parts.append(memory_context_section)
+        
         prompt = f"""Generate a comprehensive meeting brief to help prepare for an upcoming meeting.
 
 Meeting Information:
--- a/app/tools/followup.py
+++ b/app/tools/followup.py
@@ -3,6 +3,7 @@
 from typing import Dict, Any, Optional
 from app.llm.gemini_client import GeminiClient
 from app.llm.prompts import SUMMARIZATION_TOOL_PROMPT
+from app.tools.memory_processing import synthesize_memory
 
 
 class FollowUpTool:
@@ -14,6 +15,7 @@ class FollowUpTool:
     async def generate_followup(
         self,
         meeting_summary: Optional[str] = None,
         transcript: Optional[str] = None,
         meeting_title: Optional[str] = None,
         meeting_date: Optional[str] = None,
         client_name: Optional[str] = None,
         client_email: Optional[str] = None,
         attendees: Optional[str] = None,
-        action_items: Optional[list] = None,
-        decisions: Optional[list] = None
+        action_items: Optional[list] = None,
+        decisions: Optional[list] = None,
+        past_context: Optional[List[Dict[str, Any]]] = None
     ) -> Dict[str, Any]:
         """
         Generate a follow-up email.
@@ -35,6 +37,7 @@ class FollowUpTool:
             attendees: Attendees list as formatted string
             action_items: List of action items from the meeting
             decisions: List of decisions made in the meeting (can be dicts with description/context)
+            past_context: Optional list of past meeting memories for context
         
         Returns:
             Dictionary with email subject and body
         """
+        # Synthesize memory insights if past_context provided
+        insights = {
+            "communication_style": "",
+            "client_history": "",
+            "recurring_topics": "",
+            "open_loops": "",
+            "preferences": ""
+        }
+        if past_context:
+            try:
+                insights = await synthesize_memory(past_context, self.llm)
+            except Exception:
+                # Fail gracefully - continue without memory insights
+                pass
+        
+        # Build memory context section if insights exist
+        memory_context_section = ""
+        if any(insights.values()):  # Only include if at least one field has content
+            memory_context_section = f"""
+Context From Prior Meetings:
+- Communication style: {insights['communication_style']}
+- Client history: {insights['client_history']}
+- Recurring themes: {insights['recurring_topics']}
+- Open loops: {insights['open_loops']}
+- User preferences: {insights['preferences']}
+"""
+            # Enforce 1200 character limit on memory context section
+            if len(memory_context_section) > 1200:
+                memory_context_section = memory_context_section[:1200] + "..."
+        
         # Build structured context for email generation
         meeting_info_parts = []
         
@@ -92,7 +115,7 @@ class FollowUpTool:
                 action_items_text = "\n".join([f"â€¢ {item}" for item in action_items])
         
         # Build comprehensive prompt similar to summarization style
-        prompt = f"""Generate a professional follow-up email based on the meeting information below.
+        prompt = f"""Generate a professional follow-up email based on the meeting information below.
+{memory_context_section}
 
 Meeting Information:
 {chr(10).join(meeting_info_parts) if meeting_info_parts else "No meeting information provided."}

